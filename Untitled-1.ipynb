{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "page = requests.get(URL)\n",
    "        \n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Name MC_USD_Billion\n",
      "0                           JPMorgan Chase         551.03\n",
      "1                          Bank of America         288.96\n",
      "2  Industrial and Commercial Bank of China         249.28\n",
      "3                              Wells Fargo         208.41\n",
      "4               Agricultural Bank of China         207.79\n",
      "5                            Bank of China         171.35\n",
      "6                  China Construction Bank         166.19\n",
      "7                                     HSBC         164.48\n",
      "8                           Morgan Stanley         148.90\n",
      "9                                HDFC Bank         147.31\n"
     ]
    }
   ],
   "source": [
    "tables = soup.find_all('tbody')\n",
    "rows = tables[2].find_all('tr')\n",
    "count = 0\n",
    "df = pd.DataFrame(columns=[\"Name\",\"MC_USD_Billion\"])\n",
    "\n",
    "for row in rows:\n",
    "    if count >= 10:\n",
    "        break\n",
    "    col = row.find_all('td')\n",
    "\n",
    "    if col:\n",
    "        data_dict = {\"Name\": col[1].text.strip(),\n",
    "                     \"MC_USD_Billion\": col[2].text.strip()}\n",
    "        df1 = pd.DataFrame(data_dict, index=[0])\n",
    "        df = pd.concat([df,df1], ignore_index=True)\n",
    "        count=count+1\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Currency   Rate\n",
      "0      EUR   0.93\n",
      "1      GBP   0.80\n",
      "2      INR  82.95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# URL of the CSV file\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv\"\n",
    "\n",
    "# Reading the CSV file into a DataFrame\n",
    "exchange_df = pd.read_csv(url)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(exchange_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'288.96'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MC_USD_Billion'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR 0.93\n",
      "GBP 0.8\n",
      "INR 82.95\n",
      "                                      Name MC_USD_Billion  MC_EUR_Billion  \\\n",
      "0                           JPMorgan Chase         551.03        512.4579   \n",
      "1                          Bank of America         288.96        268.7328   \n",
      "2  Industrial and Commercial Bank of China         249.28        231.8304   \n",
      "3                              Wells Fargo         208.41        193.8213   \n",
      "4               Agricultural Bank of China         207.79        193.2447   \n",
      "5                            Bank of China         171.35        159.3555   \n",
      "6                  China Construction Bank         166.19        154.5567   \n",
      "7                                     HSBC         164.48        152.9664   \n",
      "8                           Morgan Stanley         148.90        138.4770   \n",
      "9                                HDFC Bank         147.31        136.9983   \n",
      "\n",
      "   MC_GBP_Billion  MC_INR_Billion  \n",
      "0         440.824      45707.9385  \n",
      "1         231.168      23969.2320  \n",
      "2         199.424      20677.7760  \n",
      "3         166.728      17287.6095  \n",
      "4         166.232      17236.1805  \n",
      "5         137.080      14213.4825  \n",
      "6         132.952      13785.4605  \n",
      "7         131.584      13643.6160  \n",
      "8         119.120      12351.2550  \n",
      "9         117.848      12219.3645  \n"
     ]
    }
   ],
   "source": [
    "for index, row in exchange_df.iterrows():\n",
    "    currency, rate = row['Currency'], row['Rate']\n",
    "    print(currency, rate)\n",
    "    df[f'MC_{currency}_Billion'] = df['MC_USD_Billion'].apply(lambda x: float(x) * rate)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EUR 0.93\n",
      "GBP 0.8\n",
      "INR 82.95\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '\\home\\project'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m df \u001b[38;5;241m=\u001b[39m transform(df,exchange_csv_url)\n\u001b[0;32m     80\u001b[0m log_progress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData transformation complete. Initiating loading process\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[43mload_to_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m log_progress(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData saved to CSV file\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     85\u001b[0m sql_connection \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBanks.db\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 44\u001b[0m, in \u001b[0;36mload_to_csv\u001b[1;34m(df, csv_path)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_to_csv\u001b[39m(df, csv_path):\n\u001b[1;32m---> 44\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\pandas\\core\\generic.py:3964\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3953\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3955\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3956\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3957\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3961\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3962\u001b[0m )\n\u001b[1;32m-> 3964\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3967\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gayat\\.conda\\envs\\pracenv\\lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '\\home\\project'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "def extract(df):\n",
    "    URL = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "    page = requests.get(URL)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all('tbody')\n",
    "    rows = tables[0].find_all('tr')\n",
    "    count = 0\n",
    "\n",
    "    for row in rows:\n",
    "        if count >= 10:\n",
    "            break\n",
    "        col = row.find_all('td')\n",
    "\n",
    "        if len(col)!=0:\n",
    "            data_dict = {\"Name\": col[1].text.strip(),\"MC_USD_Billion\": col[2].text.strip()}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count=count+1\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def transform(df,url):\n",
    "    exchange_currency_df = pd.read_csv(url)\n",
    "    for index, row in exchange_currency_df.iterrows():\n",
    "        currency, rate = row['Currency'], row['Rate']\n",
    "        print(currency, rate)\n",
    "        df[f'MC_{currency}_Billion'] = df['MC_USD_Billion'].apply(lambda x: float(x) * rate)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)\n",
    "\n",
    "\n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message at a given stage of the \n",
    "    code execution to a log file. Function returns nothing.'''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(\"./code_log.txt\",\"a\") as f: \n",
    "        f.write(timestamp + ' : ' + message + '\\n')    \n",
    "\n",
    "\n",
    "\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = 'Largest_banks_data.csv'\n",
    "df = pd.DataFrame(columns=[\"Name\",\"MC_USD_Billion\"])\n",
    "exchange_csv_url='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
    "#table_attribs = [\"Name\",\"MC_USD_Billion\"]\n",
    "\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(df)\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "df = transform(df,exchange_csv_url)\n",
    "log_progress('Data transformation complete. Initiating loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect('Banks.db')\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "# Print the contents of the entire table\n",
    "query_statement = f\"SELECT * from {table_name}\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "# Print the average market capitalization of all the banks in Billion USD.\n",
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "# Print only the names of the top 5 banks\n",
    "query_statement = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "sql_connection.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "def extract(df):\n",
    "    URL = \"https://web.archive.org/web/20230908091635/https://en.wikipedia.org/wiki/List_of_largest_banks\"\n",
    "    page = requests.get(URL)\n",
    "    \n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    tables = soup.find_all('tbody')\n",
    "    rows = tables[2].find_all('tr')\n",
    "    count = 0\n",
    "    df = pd.DataFrame(columns=[\"Name\",\"MC_USD_Billion\"])\n",
    "\n",
    "    for row in rows:\n",
    "        if count >= 10:\n",
    "            break\n",
    "        col = row.find_all('td')\n",
    "\n",
    "        if col:\n",
    "            data_dict = {\"Name\": col[1].text.strip(),\n",
    "                        \"MC_USD_Billion\": col[2].text.strip()}\n",
    "            df1 = pd.DataFrame(data_dict, index=[0])\n",
    "            df = pd.concat([df,df1], ignore_index=True)\n",
    "            count=count+1\n",
    "    return df\n",
    "    \n",
    "\n",
    "\n",
    "def transform(df,url):\n",
    "    exchange_currency_df = pd.read_csv(url)\n",
    "    for index, row in exchange_df.iterrows():\n",
    "        currency, rate = row['Currency'], row['Rate']\n",
    "        print(currency, rate)\n",
    "        df[f'MC_{currency}_Billion'] = df['MC_USD_Billion'].apply(lambda x: float(x) * rate)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_to_csv(df, csv_path):\n",
    "    df.to_csv(csv_path)\n",
    "\n",
    "def load_to_db(df, sql_connection, table_name):\n",
    "    df.to_sql(table_name, sql_connection, if_exists='replace', index=False)\n",
    "\n",
    "\n",
    "def run_query(query_statement, sql_connection):\n",
    "    print(query_statement)\n",
    "    query_output = pd.read_sql(query_statement, sql_connection)\n",
    "    print(query_output)\n",
    "\n",
    "\n",
    "def log_progress(message):\n",
    "    ''' This function logs the mentioned message at a given stage of the \n",
    "    code execution to a log file. Function returns nothing.'''\n",
    "    timestamp_format = '%Y-%h-%d-%H:%M:%S' # Year-Monthname-Day-Hour-Minute-Second \n",
    "    now = datetime.now() # get current timestamp \n",
    "    timestamp = now.strftime(timestamp_format) \n",
    "    with open(\"./etl_project_log.txt\",\"a\") as f: \n",
    "        f.write(timestamp + ' : ' + message + '\\n')    \n",
    "\n",
    "\n",
    "\n",
    "db_name = 'Banks.db'\n",
    "table_name = 'Largest_banks'\n",
    "csv_path = '/home/project/Largest_banks_data.csv'\n",
    "df = pd.DataFrame(columns=[\"Name\",\"MC_USD_Billion\",\"MC_GBP_Billion\",\"MC_EUR_Billion\",\"MC_INR_Billion\"])\n",
    "exchange_csv='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-PY0221EN-Coursera/labs/v2/exchange_rate.csv'\n",
    "#table_attribs = [\"Name\",\"MC_USD_Billion\"]\n",
    "\n",
    "log_progress('Preliminaries complete. Initiating ETL process')\n",
    "\n",
    "df = extract(df)\n",
    "log_progress('Data extraction complete. Initiating Transformation process')\n",
    "\n",
    "df = transform(df,exchange_csv_url)\n",
    "log_progress('Data transformation complete. Initiating loading process')\n",
    "\n",
    "load_to_csv(df, csv_path)\n",
    "log_progress('Data saved to CSV file')\n",
    "\n",
    "sql_connection = sqlite3.connect('Banks.db')\n",
    "log_progress('SQL Connection initiated.')\n",
    "\n",
    "load_to_db(df, sql_connection, table_name)\n",
    "log_progress('Data loaded to Database as table. Running the query')\n",
    "\n",
    "# Print the contents of the entire table\n",
    "query_statement = f\"SELECT * from {table_name}\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "# Print the average market capitalization of all the banks in Billion USD.\n",
    "query_statement = f\"SELECT AVG(MC_GBP_Billion) FROM {table_name}\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "# Print only the names of the top 5 banks\n",
    "query_statement = f\"SELECT Name from {table_name} LIMIT 5\"\n",
    "run_query(query_statement, sql_connection)\n",
    "\n",
    "log_progress('Process Complete.')\n",
    "sql_connection.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pracenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
